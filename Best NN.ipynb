{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e02fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.layers import BatchNormalization, LeakyReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f37455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a7874d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training dataset\n",
    "train_df = pd.read_csv('train.csv')\n",
    "\n",
    "# Load the test dataset\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "974c1100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step\n",
      "R2 score for fold 1: 0.875362333614408\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step\n",
      "R2 score for fold 2: 0.8767474514117136\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step\n",
      "R2 score for fold 3: 0.8832353894696784\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 512us/step\n",
      "R2 score for fold 4: 0.8760545733365399\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 597us/step\n",
      "R2 score for fold 5: 0.8816353421383687\n",
      "Average R2 score across all folds: 0.8786070179941416\n"
     ]
    }
   ],
   "source": [
    "train_df.drop('SEQN', axis=1, inplace=True)\n",
    "X = train_df.drop('y', axis=1)\n",
    "y = train_df['y']\n",
    "\n",
    "# Define preprocessing for numeric and categorical columns\n",
    "numeric_features = X.columns.drop('district').tolist()\n",
    "categorical_features = ['district']\n",
    "\n",
    "# Define the preprocessor\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', StandardScaler(), numeric_features),\n",
    "    ('cat', OneHotEncoder(), categorical_features)\n",
    "])\n",
    "\n",
    "# Define the model architecture\n",
    "def build_model(input_shape):\n",
    "    dropout_rate=0.4\n",
    "    model = Sequential([\n",
    "        Dense(256, input_shape=(input_shape,)),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(),\n",
    "        Dropout(dropout_rate),  # Adjusted dropout\n",
    "        Dense(128),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(),\n",
    "        Dropout(dropout_rate),  # Adjusted dropout\n",
    "        Dense(64),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(),\n",
    "        Dropout(dropout_rate),  # Adjusted dropout\n",
    "        Dense(32),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(),\n",
    "        Dropout(dropout_rate / 2),  # Adjusted dropout\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Prepare for k-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_var = 1\n",
    "results = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    # Apply preprocessing\n",
    "    X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "    X_val_preprocessed = preprocessor.transform(X_val)\n",
    "\n",
    "    # Build and fit the model\n",
    "    model = build_model(X_train_preprocessed.shape[1])\n",
    "    model.fit(\n",
    "        X_train_preprocessed, y_train,\n",
    "        epochs=200,\n",
    "        validation_data=(X_val_preprocessed, y_val),\n",
    "        callbacks=[EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)],\n",
    "        verbose=0  # You can set verbose=1 if you want to see progress\n",
    "    )\n",
    "\n",
    "    # Evaluate the model\n",
    "    predictions = model.predict(X_val_preprocessed)\n",
    "    r2 = r2_score(y_val, predictions)\n",
    "    results.append(r2)\n",
    "    print(f'R2 score for fold {fold_var}: {r2}')\n",
    "    fold_var += 1\n",
    "\n",
    "# Calculate average performance across all folds\n",
    "average_r2_score = np.mean(results)\n",
    "print(f'Average R2 score across all folds: {average_r2_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d68d02",
   "metadata": {},
   "source": [
    "# Preparing text output file for Kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fe39310",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv') \n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "train_df.drop('SEQN', axis=1, inplace=True)\n",
    "test_df.drop('SEQN', axis=1, inplace=True)\n",
    "\n",
    "X_train = train_df.drop('y', axis=1)\n",
    "y_train = train_df['y']\n",
    "X_test = test_df \n",
    "\n",
    "\n",
    "numeric_features = X_train.columns.drop('district').tolist()\n",
    "categorical_features = ['district']\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', StandardScaler(), numeric_features),\n",
    "    ('cat', OneHotEncoder(), categorical_features)\n",
    "])\n",
    "\n",
    "\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94c4d245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 569us/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "predictions = model.predict(X_test_preprocessed)\n",
    "test_df = pd.read_csv('test.csv')  # Update the path\n",
    "# Create a submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'SEQN': test_df['SEQN'],  # Assuming you need to include an identifier in your submission\n",
    "    'y': predictions.flatten()\n",
    "})\n",
    "\n",
    "# Save the submission file\n",
    "submission.to_csv('submit_10.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add09a9c",
   "metadata": {},
   "source": [
    "## Testing simple(ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e614ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nn = pd.read_csv(\"submit_6.csv\")\n",
    "df_lgbm = pd.read_csv(\"submit_2.csv\")\n",
    "df_nn2 = pd.read_csv(\"submit_5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e5cfcca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_predictions = df_nn['y']\n",
    "nn2_predictions = df_nn2['y']\n",
    "gb_predictions = df_lgbm['y']\n",
    "combined_predictions = 0.6 * nn_predictions + 0.1 * gb_predictions +  0.3 * nn2_predictions\n",
    "test_df = pd.read_csv('test.csv')  # Update the path\n",
    "# Create a submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'SEQN': test_df['SEQN'],  # Assuming you need to include an identifier in your submission\n",
    "    'y': combined_predictions\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51498097",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submit_9.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb7b759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab52da03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
